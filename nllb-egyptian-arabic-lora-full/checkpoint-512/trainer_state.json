{
  "best_global_step": 512,
  "best_metric": 7.157197952270508,
  "best_model_checkpoint": "./nllb-egyptian-arabic-lora-full\\checkpoint-512",
  "epoch": 0.40594648166501485,
  "eval_steps": 64,
  "global_step": 512,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03964321110009911,
      "grad_norm": 0.4896185100078583,
      "learning_rate": 0.00029148580968280465,
      "loss": 12.4838,
      "step": 50
    },
    {
      "epoch": 0.050743310208126856,
      "eval_loss": 10.53719425201416,
      "eval_runtime": 1718.8813,
      "eval_samples_per_second": 1.305,
      "eval_steps_per_second": 0.326,
      "step": 64
    },
    {
      "epoch": 0.07928642220019821,
      "grad_norm": 0.457127183675766,
      "learning_rate": 0.00026644407345575955,
      "loss": 9.9676,
      "step": 100
    },
    {
      "epoch": 0.10148662041625371,
      "eval_loss": 7.654378890991211,
      "eval_runtime": 1718.2917,
      "eval_samples_per_second": 1.305,
      "eval_steps_per_second": 0.326,
      "step": 128
    },
    {
      "epoch": 0.11892963330029732,
      "grad_norm": 0.20653663575649261,
      "learning_rate": 0.0002414023372287145,
      "loss": 8.0095,
      "step": 150
    },
    {
      "epoch": 0.1522299306243806,
      "eval_loss": 7.28108024597168,
      "eval_runtime": 1718.5217,
      "eval_samples_per_second": 1.305,
      "eval_steps_per_second": 0.326,
      "step": 192
    },
    {
      "epoch": 0.15857284440039643,
      "grad_norm": 0.141741544008255,
      "learning_rate": 0.00021636060100166943,
      "loss": 7.5532,
      "step": 200
    },
    {
      "epoch": 0.19821605550049554,
      "grad_norm": 0.1396407037973404,
      "learning_rate": 0.00019131886477462436,
      "loss": 7.4337,
      "step": 250
    },
    {
      "epoch": 0.20297324083250742,
      "eval_loss": 7.218786239624023,
      "eval_runtime": 1718.9678,
      "eval_samples_per_second": 1.305,
      "eval_steps_per_second": 0.326,
      "step": 256
    },
    {
      "epoch": 0.23785926660059464,
      "grad_norm": 0.11677642911672592,
      "learning_rate": 0.00016627712854757929,
      "loss": 7.3864,
      "step": 300
    },
    {
      "epoch": 0.2537165510406343,
      "eval_loss": 7.195451736450195,
      "eval_runtime": 1719.259,
      "eval_samples_per_second": 1.305,
      "eval_steps_per_second": 0.326,
      "step": 320
    },
    {
      "epoch": 0.27750247770069375,
      "grad_norm": 0.10610303282737732,
      "learning_rate": 0.0001412353923205342,
      "loss": 7.3603,
      "step": 350
    },
    {
      "epoch": 0.3044598612487612,
      "eval_loss": 7.17975378036499,
      "eval_runtime": 1719.4284,
      "eval_samples_per_second": 1.305,
      "eval_steps_per_second": 0.326,
      "step": 384
    },
    {
      "epoch": 0.31714568880079286,
      "grad_norm": 0.1342497020959854,
      "learning_rate": 0.00011619365609348914,
      "loss": 7.3256,
      "step": 400
    },
    {
      "epoch": 0.355203171456888,
      "eval_loss": 7.166705131530762,
      "eval_runtime": 1719.8234,
      "eval_samples_per_second": 1.304,
      "eval_steps_per_second": 0.326,
      "step": 448
    },
    {
      "epoch": 0.35678889990089196,
      "grad_norm": 0.12910926342010498,
      "learning_rate": 9.115191986644407e-05,
      "loss": 7.3353,
      "step": 450
    },
    {
      "epoch": 0.39643211100099107,
      "grad_norm": 0.1373981237411499,
      "learning_rate": 6.611018363939899e-05,
      "loss": 7.2939,
      "step": 500
    },
    {
      "epoch": 0.40594648166501485,
      "eval_loss": 7.157197952270508,
      "eval_runtime": 1717.9787,
      "eval_samples_per_second": 1.306,
      "eval_steps_per_second": 0.327,
      "step": 512
    }
  ],
  "logging_steps": 50,
  "max_steps": 631,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 64,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2230247667793920.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
